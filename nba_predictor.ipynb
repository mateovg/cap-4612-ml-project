{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_id</th>\n",
       "      <th>team_id_home</th>\n",
       "      <th>team_abbreviation_home</th>\n",
       "      <th>team_name_home</th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>wl_home</th>\n",
       "      <th>fgm_home</th>\n",
       "      <th>fga_home</th>\n",
       "      <th>fg_pct_home</th>\n",
       "      <th>...</th>\n",
       "      <th>dreb_away</th>\n",
       "      <th>reb_away</th>\n",
       "      <th>ast_away</th>\n",
       "      <th>stl_away</th>\n",
       "      <th>blk_away</th>\n",
       "      <th>tov_away</th>\n",
       "      <th>pf_away</th>\n",
       "      <th>pts_away</th>\n",
       "      <th>plus_minus_away</th>\n",
       "      <th>elo_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21981</td>\n",
       "      <td>1610612749</td>\n",
       "      <td>MIL</td>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "      <td>28100518</td>\n",
       "      <td>1982-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>43.50</td>\n",
       "      <td>92.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>38.50</td>\n",
       "      <td>20.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>89.50</td>\n",
       "      <td>-19.00</td>\n",
       "      <td>1361.309587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21981</td>\n",
       "      <td>1610612741</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>28100564</td>\n",
       "      <td>1982-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>92.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>18.33</td>\n",
       "      <td>40.67</td>\n",
       "      <td>24.00</td>\n",
       "      <td>8.67</td>\n",
       "      <td>6.33</td>\n",
       "      <td>20.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>99.67</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>1652.547934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21981</td>\n",
       "      <td>1610612751</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>28100625</td>\n",
       "      <td>1982-02-24</td>\n",
       "      <td>0</td>\n",
       "      <td>40.25</td>\n",
       "      <td>90.75</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>19.50</td>\n",
       "      <td>40.25</td>\n",
       "      <td>22.75</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.25</td>\n",
       "      <td>22.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>103.00</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1673.129963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21981</td>\n",
       "      <td>1610612749</td>\n",
       "      <td>MIL</td>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "      <td>28100656</td>\n",
       "      <td>1982-03-02</td>\n",
       "      <td>1</td>\n",
       "      <td>40.80</td>\n",
       "      <td>90.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>21.00</td>\n",
       "      <td>42.20</td>\n",
       "      <td>22.00</td>\n",
       "      <td>10.40</td>\n",
       "      <td>5.20</td>\n",
       "      <td>22.00</td>\n",
       "      <td>27.4</td>\n",
       "      <td>100.60</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>1479.863124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21981</td>\n",
       "      <td>1610612759</td>\n",
       "      <td>SAN</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>28100679</td>\n",
       "      <td>1982-03-06</td>\n",
       "      <td>1</td>\n",
       "      <td>45.33</td>\n",
       "      <td>94.33</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>22.33</td>\n",
       "      <td>41.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>10.33</td>\n",
       "      <td>4.83</td>\n",
       "      <td>20.17</td>\n",
       "      <td>28.5</td>\n",
       "      <td>111.50</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>1682.372699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season_id  team_id_home team_abbreviation_home     team_name_home  \\\n",
       "0      21981    1610612749                    MIL    Milwaukee Bucks   \n",
       "1      21981    1610612741                    CHI      Chicago Bulls   \n",
       "2      21981    1610612751                    NJN    New Jersey Nets   \n",
       "3      21981    1610612749                    MIL    Milwaukee Bucks   \n",
       "4      21981    1610612759                    SAN  San Antonio Spurs   \n",
       "\n",
       "    game_id   game_date  wl_home  fgm_home  fga_home  fg_pct_home  ...  \\\n",
       "0  28100518  1982-02-05        1     43.50     92.00         0.48  ...   \n",
       "1  28100564  1982-02-13        0     40.00     92.33         0.44  ...   \n",
       "2  28100625  1982-02-24        0     40.25     90.75         0.45  ...   \n",
       "3  28100656  1982-03-02        1     40.80     90.00         0.46  ...   \n",
       "4  28100679  1982-03-06        1     45.33     94.33         0.48  ...   \n",
       "\n",
       "   dreb_away  reb_away  ast_away  stl_away  blk_away  tov_away  pf_away  \\\n",
       "0      13.50     38.50     20.50      4.50      4.00     20.00     28.0   \n",
       "1      18.33     40.67     24.00      8.67      6.33     20.00     28.0   \n",
       "2      19.50     40.25     22.75     11.00      6.25     22.00     28.0   \n",
       "3      21.00     42.20     22.00     10.40      5.20     22.00     27.4   \n",
       "4      22.33     41.00     24.00     10.33      4.83     20.17     28.5   \n",
       "\n",
       "   pts_away  plus_minus_away     elo_away  \n",
       "0     89.50           -19.00  1361.309587  \n",
       "1     99.67            -2.67  1652.547934  \n",
       "2    103.00            -0.25  1673.129963  \n",
       "3    100.60            -2.20  1479.863124  \n",
       "4    111.50            -2.67  1682.372699  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_games = pd.read_csv('data/games_rolling.csv')\n",
    "df_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wl_home</th>\n",
       "      <th>fgm_home</th>\n",
       "      <th>fga_home</th>\n",
       "      <th>fg_pct_home</th>\n",
       "      <th>fg3m_home</th>\n",
       "      <th>fg3a_home</th>\n",
       "      <th>fg3_pct_home</th>\n",
       "      <th>ftm_home</th>\n",
       "      <th>fta_home</th>\n",
       "      <th>ft_pct_home</th>\n",
       "      <th>...</th>\n",
       "      <th>dreb_away</th>\n",
       "      <th>reb_away</th>\n",
       "      <th>ast_away</th>\n",
       "      <th>stl_away</th>\n",
       "      <th>blk_away</th>\n",
       "      <th>tov_away</th>\n",
       "      <th>pf_away</th>\n",
       "      <th>pts_away</th>\n",
       "      <th>plus_minus_away</th>\n",
       "      <th>elo_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43.50</td>\n",
       "      <td>92.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>20.50</td>\n",
       "      <td>31.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>38.50</td>\n",
       "      <td>20.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>89.50</td>\n",
       "      <td>-19.00</td>\n",
       "      <td>1361.309587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>92.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.54</td>\n",
       "      <td>20.67</td>\n",
       "      <td>30.33</td>\n",
       "      <td>0.69</td>\n",
       "      <td>...</td>\n",
       "      <td>18.33</td>\n",
       "      <td>40.67</td>\n",
       "      <td>24.00</td>\n",
       "      <td>8.67</td>\n",
       "      <td>6.33</td>\n",
       "      <td>20.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>99.67</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>1652.547934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40.25</td>\n",
       "      <td>90.75</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.75</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>21.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>19.50</td>\n",
       "      <td>40.25</td>\n",
       "      <td>22.75</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.25</td>\n",
       "      <td>22.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>103.00</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1673.129963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>40.80</td>\n",
       "      <td>90.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.40</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.39</td>\n",
       "      <td>19.80</td>\n",
       "      <td>27.60</td>\n",
       "      <td>0.73</td>\n",
       "      <td>...</td>\n",
       "      <td>21.00</td>\n",
       "      <td>42.20</td>\n",
       "      <td>22.00</td>\n",
       "      <td>10.40</td>\n",
       "      <td>5.20</td>\n",
       "      <td>22.00</td>\n",
       "      <td>27.4</td>\n",
       "      <td>100.60</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>1479.863124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>45.33</td>\n",
       "      <td>94.33</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.33</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>22.17</td>\n",
       "      <td>29.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>22.33</td>\n",
       "      <td>41.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>10.33</td>\n",
       "      <td>4.83</td>\n",
       "      <td>20.17</td>\n",
       "      <td>28.5</td>\n",
       "      <td>111.50</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>1682.372699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wl_home  fgm_home  fga_home  fg_pct_home  fg3m_home  fg3a_home  \\\n",
       "0        1     43.50     92.00         0.48       1.00       2.00   \n",
       "1        0     40.00     92.33         0.44       1.67       4.67   \n",
       "2        0     40.25     90.75         0.45       1.75       5.00   \n",
       "3        1     40.80     90.00         0.46       1.40       4.20   \n",
       "4        1     45.33     94.33         0.48       1.33       4.00   \n",
       "\n",
       "   fg3_pct_home  ftm_home  fta_home  ft_pct_home  ...  dreb_away  reb_away  \\\n",
       "0          0.67     20.50     31.00         0.67  ...      13.50     38.50   \n",
       "1          0.54     20.67     30.33         0.69  ...      18.33     40.67   \n",
       "2          0.49     21.00     30.00         0.71  ...      19.50     40.25   \n",
       "3          0.39     19.80     27.60         0.73  ...      21.00     42.20   \n",
       "4          0.38     22.17     29.50         0.75  ...      22.33     41.00   \n",
       "\n",
       "   ast_away  stl_away  blk_away  tov_away  pf_away  pts_away  plus_minus_away  \\\n",
       "0     20.50      4.50      4.00     20.00     28.0     89.50           -19.00   \n",
       "1     24.00      8.67      6.33     20.00     28.0     99.67            -2.67   \n",
       "2     22.75     11.00      6.25     22.00     28.0    103.00            -0.25   \n",
       "3     22.00     10.40      5.20     22.00     27.4    100.60            -2.20   \n",
       "4     24.00     10.33      4.83     20.17     28.5    111.50            -2.67   \n",
       "\n",
       "      elo_away  \n",
       "0  1361.309587  \n",
       "1  1652.547934  \n",
       "2  1673.129963  \n",
       "3  1479.863124  \n",
       "4  1682.372699  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop non-numeric columns\n",
    "df_games = df_games.select_dtypes(include=['float64', 'int64'])\n",
    "df_games.drop(['season_id', 'team_id_home', 'game_id', 'team_id_away'], axis=1, inplace=True)\n",
    "df_games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will separate the features from the target data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41865 games with 40 features\n",
      "Index(['fgm_home', 'fga_home', 'fg_pct_home', 'fg3m_home', 'fg3a_home',\n",
      "       'fg3_pct_home', 'ftm_home', 'fta_home', 'ft_pct_home', 'oreb_home',\n",
      "       'dreb_home', 'reb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home',\n",
      "       'pf_home', 'pts_home', 'plus_minus_home', 'elo_home', 'fgm_away',\n",
      "       'fga_away', 'fg_pct_away', 'fg3m_away', 'fg3a_away', 'fg3_pct_away',\n",
      "       'ftm_away', 'fta_away', 'ft_pct_away', 'oreb_away', 'dreb_away',\n",
      "       'reb_away', 'ast_away', 'stl_away', 'blk_away', 'tov_away', 'pf_away',\n",
      "       'pts_away', 'plus_minus_away', 'elo_away'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "features = df_games.drop(columns=['wl_home', 'wl_away'])\n",
    "target = df_games['wl_home']\n",
    "\n",
    "print(f\"{features.shape[0]} games with {features.shape[1]} features\")\n",
    "print(features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy of the model will be predicting the home team always wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6023886301206258\n",
      "Precision: 0.6023886301206258\n",
      "Recall: 1.0\n",
      "F1 Score: 0.751863335519647\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def find_metrics(labels, preds):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision': precision_score(labels, preds),\n",
    "        'recall': recall_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds)\n",
    "    }\n",
    "\n",
    "def print_metrics(labels, preds):\n",
    "    metrics = find_metrics(labels, preds)\n",
    "    print(f\"Accuracy: {metrics['accuracy']}\")\n",
    "    print(f\"Precision: {metrics['precision']}\")\n",
    "    print(f\"Recall: {metrics['recall']}\")\n",
    "    print(f\"F1 Score: {metrics['f1']}\")\n",
    "\n",
    "# baseline model\n",
    "baseline_preds = [1] * len(target) # home team always wins\n",
    "print_metrics(target, baseline_preds)\n",
    "\n",
    "# elo predictions, elo_home + 100 > elo_away\n",
    "elo_preds = [1 if x + 100 > y else 0 for (x,y) in zip(features['elo_home'], features['elo_away'])]\n",
    "# print_metrics(target, elo_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fgm_home', 'fga_home', 'fg_pct_home', 'fg3m_home', 'fg3a_home',\n",
       "       'fg3_pct_home', 'ftm_home', 'fta_home', 'ft_pct_home', 'oreb_home',\n",
       "       'dreb_home', 'reb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home',\n",
       "       'pf_home', 'pts_home', 'plus_minus_home', 'elo_home', 'fgm_away',\n",
       "       'fga_away', 'fg_pct_away', 'fg3m_away', 'fg3a_away', 'fg3_pct_away',\n",
       "       'ftm_away', 'fta_away', 'ft_pct_away', 'oreb_away', 'dreb_away',\n",
       "       'reb_away', 'ast_away', 'stl_away', 'blk_away', 'tov_away', 'pf_away',\n",
       "       'pts_away', 'plus_minus_away', 'elo_away'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `StandardScalar` from `sklearn.preprocessing`, which standardizes data with it's z-score for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series split for cross validation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "def train(model, cv = tscv, n_splits = 5, X = features, y = target, scaler=scaler):\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    for train_index, test_index in tscv.split(features_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        # print_metrics(y_test, preds)\n",
    "    return find_metrics(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5817686684821557\n",
      "Precision: 0.7072293097808309\n",
      "Recall: 0.5166069295101553\n",
      "F1 Score: 0.5970726318696493\n",
      "Accuracy: 0.5455066647556256\n",
      "Precision: 0.7013422818791947\n",
      "Recall: 0.442484121383204\n",
      "F1 Score: 0.5426222414539161\n",
      "Accuracy: 0.5423534470402752\n",
      "Precision: 0.6920077972709552\n",
      "Recall: 0.42484442316898036\n",
      "F1 Score: 0.5264718967818478\n",
      "Accuracy: 0.568582485308872\n",
      "Precision: 0.6937679083094556\n",
      "Recall: 0.47336265884652984\n",
      "F1 Score: 0.5627542126670539\n",
      "Accuracy: 0.5437867278199799\n",
      "Precision: 0.6693262411347518\n",
      "Recall: 0.38256903977704587\n",
      "F1 Score: 0.4868611961953894\n",
      "Accuracy: 0.6303568869141465\n",
      "Precision: 0.666943866943867\n",
      "Recall: 0.766547192353644\n",
      "F1 Score: 0.7132851584213453\n",
      "Accuracy: 0.6120108929339257\n",
      "Precision: 0.6744238590149119\n",
      "Recall: 0.7021877205363444\n",
      "F1 Score: 0.6880258153739771\n",
      "Accuracy: 0.6141608141034829\n",
      "Precision: 0.6686336813436223\n",
      "Recall: 0.7051220679751077\n",
      "F1 Score: 0.6863932898415657\n",
      "Accuracy: 0.6230471549376523\n",
      "Precision: 0.6624444444444444\n",
      "Recall: 0.728494623655914\n",
      "F1 Score: 0.693901303538175\n",
      "Accuracy: 0.5872151354450337\n",
      "Precision: 0.6326784381994529\n",
      "Recall: 0.6445401570813276\n",
      "F1 Score: 0.6385542168674698\n",
      "Accuracy: 0.6216138741579476\n",
      "Precision: 0.6992519989682744\n",
      "Recall: 0.6477897252090801\n",
      "F1 Score: 0.6725378318035227\n",
      "Accuracy: 0.5910849935502365\n",
      "Precision: 0.7049853372434017\n",
      "Recall: 0.5655139967066573\n",
      "F1 Score: 0.6275943088369664\n",
      "Accuracy: 0.5859251827432994\n",
      "Precision: 0.6947718343910547\n",
      "Recall: 0.5502632838678794\n",
      "F1 Score: 0.6141311606785095\n",
      "Accuracy: 0.61330084563566\n",
      "Precision: 0.6964487034949267\n",
      "Recall: 0.60386119257087\n",
      "F1 Score: 0.6468586387434555\n",
      "Accuracy: 0.5687258133868425\n",
      "Precision: 0.6627342123525329\n",
      "Recall: 0.4839118317709653\n",
      "F1 Score: 0.5593791184653683\n",
      "Accuracy: 0.6398165400601978\n",
      "Precision: 0.6678040947410678\n",
      "Recall: 0.7949820788530466\n",
      "F1 Score: 0.725864514017672\n",
      "Accuracy: 0.6309301992260283\n",
      "Precision: 0.6824118415324336\n",
      "Recall: 0.7374735356386732\n",
      "F1 Score: 0.7088750706613907\n",
      "Accuracy: 0.6188906406765086\n",
      "Precision: 0.6660109289617486\n",
      "Recall: 0.7292963140258497\n",
      "F1 Score: 0.6962184393922084\n",
      "Accuracy: 0.6353733696431131\n",
      "Precision: 0.6658808401200171\n",
      "Recall: 0.759286412512219\n",
      "F1 Score: 0.7095227220826672\n",
      "Accuracy: 0.5930915866418232\n",
      "Precision: 0.6344660194174757\n",
      "Recall: 0.6622751456802635\n",
      "F1 Score: 0.6480723937027396\n",
      "Accuracy: 0.6368066504228178\n",
      "Precision: 0.6943724982340476\n",
      "Recall: 0.7046594982078853\n",
      "F1 Score: 0.6994781783681214\n",
      "Accuracy: 0.6177440160527448\n",
      "Precision: 0.708421052631579\n",
      "Recall: 0.6332627617031287\n",
      "F1 Score: 0.6687368028816296\n",
      "Accuracy: 0.6052744732693135\n",
      "Precision: 0.6922246220302376\n",
      "Recall: 0.6136907611297271\n",
      "F1 Score: 0.6505962953565084\n",
      "Accuracy: 0.6287802780564713\n",
      "Precision: 0.6915816326530613\n",
      "Recall: 0.6625122189638318\n",
      "F1 Score: 0.6767348976535197\n",
      "Accuracy: 0.5903683531603842\n",
      "Precision: 0.6663611365719523\n",
      "Recall: 0.5525715733468457\n",
      "F1 Score: 0.6041551246537396\n",
      "Accuracy: 0.65257273899957\n",
      "Precision: 0.6733608978145305\n",
      "Recall: 0.8172043010752689\n",
      "F1 Score: 0.7383419689119171\n",
      "Accuracy: 0.6409631646839616\n",
      "Precision: 0.6860613810741688\n",
      "Recall: 0.7572335920959774\n",
      "F1 Score: 0.7198926534719894\n",
      "Accuracy: 0.6319334957718217\n",
      "Precision: 0.6723030821917808\n",
      "Recall: 0.7517951172809957\n",
      "F1 Score: 0.7098305084745763\n",
      "Accuracy: 0.6422531173856959\n",
      "Precision: 0.6670154876517371\n",
      "Recall: 0.7788367546432062\n",
      "F1 Score: 0.7186020293122887\n",
      "Accuracy: 0.610577612154221\n",
      "Precision: 0.6436244745446054\n",
      "Recall: 0.6982518368381049\n",
      "F1 Score: 0.669826224328594\n",
      "Accuracy: 0.646839615880751\n",
      "Precision: 0.6927211646136618\n",
      "Recall: 0.739068100358423\n",
      "F1 Score: 0.7151445086705202\n",
      "Accuracy: 0.6313601834599398\n",
      "Precision: 0.7071305206020232\n",
      "Recall: 0.6741943072218302\n",
      "F1 Score: 0.6902697495183044\n",
      "Accuracy: 0.6227604987817114\n",
      "Precision: 0.6952020202020202\n",
      "Recall: 0.6589277166108186\n",
      "F1 Score: 0.6765790120422709\n",
      "Accuracy: 0.6380966031245521\n",
      "Precision: 0.6876646706586826\n",
      "Recall: 0.7016129032258065\n",
      "F1 Score: 0.6945687673884118\n",
      "Accuracy: 0.6029812240217859\n",
      "Precision: 0.6676160637994873\n",
      "Recall: 0.5938687610843679\n",
      "F1 Score: 0.6285867524805578\n",
      "Accuracy: 0.6560126128708614\n",
      "Precision: 0.6729986431478969\n",
      "Recall: 0.8296296296296296\n",
      "F1 Score: 0.7431506849315069\n",
      "Accuracy: 0.644116382399312\n",
      "Precision: 0.6838602329450915\n",
      "Recall: 0.7734650670430487\n",
      "F1 Score: 0.7259079368583728\n",
      "Accuracy: 0.6479862405045148\n",
      "Precision: 0.6802763819095478\n",
      "Recall: 0.7776448061273337\n",
      "F1 Score: 0.7257091802546348\n",
      "Accuracy: 0.6497061774401606\n",
      "Precision: 0.6696171263894607\n",
      "Recall: 0.7949657869012707\n",
      "F1 Score: 0.726927374301676\n",
      "Accuracy: 0.61631073527304\n",
      "Precision: 0.6467190388170055\n",
      "Recall: 0.7091461869774512\n",
      "F1 Score: 0.6764954682779456\n",
      "Accuracy: 0.6562992690268024\n",
      "Precision: 0.6916970607165844\n",
      "Recall: 0.7703703703703704\n",
      "F1 Score: 0.728917024643907\n",
      "Accuracy: 0.6375232908126702\n",
      "Precision: 0.703257790368272\n",
      "Recall: 0.7007762879322512\n",
      "F1 Score: 0.7020148462354189\n",
      "Accuracy: 0.6418231331517844\n",
      "Precision: 0.7031212194531817\n",
      "Recall: 0.6955481091431307\n",
      "F1 Score: 0.6993141619540368\n",
      "Accuracy: 0.6488462089723377\n",
      "Precision: 0.6910190786412285\n",
      "Recall: 0.7258064516129032\n",
      "F1 Score: 0.7079856972586412\n",
      "Accuracy: 0.6128708614017486\n",
      "Precision: 0.6667558886509636\n",
      "Recall: 0.6311122371421333\n",
      "F1 Score: 0.6484446179877652\n",
      "Accuracy: 0.6630356886914146\n",
      "Precision: 0.6747998475028594\n",
      "Recall: 0.8458781362007168\n",
      "F1 Score: 0.7507157247375676\n",
      "Accuracy: 0.6521427547656586\n",
      "Precision: 0.6886636326023997\n",
      "Recall: 0.7831098565043519\n",
      "F1 Score: 0.7328563566318106\n",
      "Accuracy: 0.6535760355453634\n",
      "Precision: 0.6825627202985693\n",
      "Recall: 0.7879368118717089\n",
      "F1 Score: 0.731474280635485\n",
      "Accuracy: 0.6555826286369499\n",
      "Precision: 0.6723117731075291\n",
      "Recall: 0.805229716520039\n",
      "F1 Score: 0.7327921716890914\n",
      "Accuracy: 0.6171707037408628\n",
      "Precision: 0.6444746376811594\n",
      "Recall: 0.7210539650367368\n",
      "F1 Score: 0.6806170034676551\n",
      "Accuracy: 0.6590225025082413\n",
      "Precision: 0.687344398340249\n",
      "Recall: 0.791636798088411\n",
      "F1 Score: 0.7358134369794558\n",
      "Accuracy: 0.6487028808943672\n",
      "Precision: 0.7059496567505721\n",
      "Recall: 0.7257115972712302\n",
      "F1 Score: 0.7156942350075398\n",
      "Accuracy: 0.6524294109215996\n",
      "Precision: 0.7023782036481182\n",
      "Recall: 0.7280995691718526\n",
      "F1 Score: 0.7150076389705018\n",
      "Accuracy: 0.6541493478572452\n",
      "Precision: 0.6877656005367927\n",
      "Recall: 0.751466275659824\n",
      "F1 Score: 0.7182062361321966\n",
      "Accuracy: 0.6107209402321915\n",
      "Precision: 0.6585931460963669\n",
      "Recall: 0.6475804408411452\n",
      "F1 Score: 0.6530403679100664\n",
      "Accuracy: 0.6597391428980938\n",
      "Precision: 0.670816827013771\n",
      "Recall: 0.8497013142174432\n",
      "F1 Score: 0.7497364537212733\n",
      "Accuracy: 0.6555826286369499\n",
      "Precision: 0.6894218942189422\n",
      "Recall: 0.7911079745942131\n",
      "F1 Score: 0.7367729214590863\n",
      "Accuracy: 0.6587358463523004\n",
      "Precision: 0.6849145914797283\n",
      "Recall: 0.7965533748204883\n",
      "F1 Score: 0.7365276087197079\n",
      "Accuracy: 0.6557259567149204\n",
      "Precision: 0.6714691558441559\n",
      "Recall: 0.8086510263929618\n",
      "F1 Score: 0.7337028824833702\n",
      "Accuracy: 0.6197506091443313\n",
      "Precision: 0.6451323463436519\n",
      "Recall: 0.7286546744362807\n",
      "F1 Score: 0.6843545508625819\n",
      "Accuracy: 0.6604557832879461\n",
      "Precision: 0.6842532467532467\n",
      "Recall: 0.8057347670250896\n",
      "F1 Score: 0.7400416986722265\n",
      "Accuracy: 0.6505661459079833\n",
      "Precision: 0.7027510624021471\n",
      "Recall: 0.7391202070101153\n",
      "F1 Score: 0.7204769548268746\n",
      "Accuracy: 0.655869284792891\n",
      "Precision: 0.7017942312059959\n",
      "Recall: 0.739588319770225\n",
      "F1 Score: 0.7201957813774619\n",
      "Accuracy: 0.6595958148201233\n",
      "Precision: 0.6888888888888889\n",
      "Recall: 0.7651515151515151\n",
      "F1 Score: 0.7250202616649299\n",
      "Accuracy: 0.6143041421814533\n",
      "Precision: 0.6568431568431569\n",
      "Recall: 0.6663288573600202\n",
      "F1 Score: 0.6615520060369764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn_tests = {x: train(KNeighborsClassifier(n_neighbors=x)) for x in range(2,15)}\n",
    "\n",
    "# print_metrics(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first I was getting almost 90% accuracy from the KNN classifier. This was caused because there was a \"wl_away\" column in the features that I did not account for. It was an artifact from the preprocessing process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([''], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m tscv \u001b[39m=\u001b[39m TimeSeriesSplit(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m      6\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline([(\u001b[39m'\u001b[39m\u001b[39mscaler\u001b[39m\u001b[39m'\u001b[39m, StandardScaler()), (\u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m, RandomForestClassifier())])\n\u001b[1;32m----> 8\u001b[0m X \u001b[39m=\u001b[39m features[[\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n\u001b[0;32m      9\u001b[0m y \u001b[39m=\u001b[39m target\n\u001b[0;32m     10\u001b[0m rfc \u001b[39m=\u001b[39m RandomForestClassifier()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5876\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5878\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5880\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5935\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5933\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5934\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5937\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   5938\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([''], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('classifier', RandomForestClassifier())])\n",
    "\n",
    "X = features[['']]\n",
    "y = target\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = features_scaled[train_index], features_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    rfc.fit(X_train, y_train)\n",
    "    preds = rfc.predict(X_test)\n",
    "print_metrics(y_test, preds)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression and the SVM with a linear kernel both performed better than the baseline. We will try to improve both models using their hyperparameters. From https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m rfc \u001b[39m=\u001b[39m RandomForestClassifier()\n\u001b[0;32m      7\u001b[0m sfs \u001b[39m=\u001b[39m SequentialFeatureSelector(rfc, n_features_to_select\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, cv\u001b[39m=\u001b[39mcv, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m sfs\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[0;32m     10\u001b[0m \u001b[39m# get the best features\u001b[39;00m\n\u001b[0;32m     11\u001b[0m best_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mcolumns[sfs\u001b[39m.\u001b[39mget_support()]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_selection\\_sequential.py:246\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    244\u001b[0m is_auto_select \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_to_select \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    245\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_iterations):\n\u001b[1;32m--> 246\u001b[0m     new_feature_idx, new_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_best_new_feature_score(\n\u001b[0;32m    247\u001b[0m         cloned_estimator, X, y, cv, current_mask\n\u001b[0;32m    248\u001b[0m     )\n\u001b[0;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m is_auto_select \u001b[39mand\u001b[39;00m ((new_score \u001b[39m-\u001b[39m old_score) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol):\n\u001b[0;32m    250\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_selection\\_sequential.py:277\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[1;34m(self, estimator, X, y, cv, current_mask)\u001b[0m\n\u001b[0;32m    275\u001b[0m         candidate_mask \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mcandidate_mask\n\u001b[0;32m    276\u001b[0m     X_new \u001b[39m=\u001b[39m X[:, candidate_mask]\n\u001b[1;32m--> 277\u001b[0m     scores[feature_idx] \u001b[39m=\u001b[39m cross_val_score(\n\u001b[0;32m    278\u001b[0m         estimator,\n\u001b[0;32m    279\u001b[0m         X_new,\n\u001b[0;32m    280\u001b[0m         y,\n\u001b[0;32m    281\u001b[0m         cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    282\u001b[0m         scoring\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscoring,\n\u001b[0;32m    283\u001b[0m         n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    284\u001b[0m     )\u001b[39m.\u001b[39mmean()\n\u001b[0;32m    285\u001b[0m new_feature_idx \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(scores, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[0;32m    286\u001b[0m \u001b[39mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    564\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    565\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    566\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    568\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    574\u001b[0m )\n\u001b[0;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[0;32m    312\u001b[0m         X,\n\u001b[0;32m    313\u001b[0m         y,\n\u001b[0;32m    314\u001b[0m         scorers,\n\u001b[0;32m    315\u001b[0m         train,\n\u001b[0;32m    316\u001b[0m         test,\n\u001b[0;32m    317\u001b[0m         verbose,\n\u001b[0;32m    318\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    319\u001b[0m         fit_params,\n\u001b[0;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1944\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1938\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1939\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1941\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1942\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1944\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1587\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1584\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1586\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1587\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1589\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1590\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1591\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1592\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1593\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[0;32m   1698\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1699\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[0;32m   1700\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# find best features using SequentialFeatureSelector\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "sfs = SequentialFeatureSelector(rfc, n_features_to_select=10, cv=cv, n_jobs=-1)\n",
    "sfs.fit(X, y)\n",
    "\n",
    "# get the best features\n",
    "best_features = X.columns[sfs.get_support()]\n",
    "X = X[best_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mateo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "# try a neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=1000, random_state=42)\n",
    "\n",
    "for train_index, test_index in tscv.split(features_scaled):\n",
    "    X_train, X_test = features_scaled[train_index], features_scaled[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    mlp.fit(X_train, y_train)\n",
    "    preds = mlp.predict(X_test)\n",
    "    \n",
    "print_metrics(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

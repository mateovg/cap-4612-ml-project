{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    df_games = pd.read_csv('data/games_rolling.csv')\n",
    "    df_games = df_games.select_dtypes(include=['float64', 'int64'])\n",
    "    # df_games.drop(['season_id', 'team_id_home', 'game_id', 'team_id_away'], axis=1, inplace=True)\n",
    "    # df_games.drop(['team_id_home', 'game_id', 'team_id_away'], axis=1, inplace=True)\n",
    "    return df_games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will separate the features from the target data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40579 games with 41 features\n",
      "Index(['season_id', 'fgm_home', 'fga_home', 'fg_pct_home', 'fg3m_home',\n",
      "       'fg3a_home', 'fg3_pct_home', 'ftm_home', 'fta_home', 'ft_pct_home',\n",
      "       'oreb_home', 'dreb_home', 'reb_home', 'ast_home', 'stl_home',\n",
      "       'blk_home', 'tov_home', 'pf_home', 'pts_home', 'plus_minus_home',\n",
      "       'elo_home', 'fgm_away', 'fga_away', 'fg_pct_away', 'fg3m_away',\n",
      "       'fg3a_away', 'fg3_pct_away', 'ftm_away', 'fta_away', 'ft_pct_away',\n",
      "       'oreb_away', 'dreb_away', 'reb_away', 'ast_away', 'stl_away',\n",
      "       'blk_away', 'tov_away', 'pf_away', 'pts_away', 'plus_minus_away',\n",
      "       'elo_away'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40579 entries, 0 to 40578\n",
      "Data columns (total 41 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   season_id        40579 non-null  int64  \n",
      " 1   fgm_home         40579 non-null  float64\n",
      " 2   fga_home         40579 non-null  float64\n",
      " 3   fg_pct_home      40579 non-null  float64\n",
      " 4   fg3m_home        40579 non-null  float64\n",
      " 5   fg3a_home        40579 non-null  float64\n",
      " 6   fg3_pct_home     40579 non-null  float64\n",
      " 7   ftm_home         40579 non-null  float64\n",
      " 8   fta_home         40579 non-null  float64\n",
      " 9   ft_pct_home      40579 non-null  float64\n",
      " 10  oreb_home        40579 non-null  float64\n",
      " 11  dreb_home        40579 non-null  float64\n",
      " 12  reb_home         40579 non-null  float64\n",
      " 13  ast_home         40579 non-null  float64\n",
      " 14  stl_home         40579 non-null  float64\n",
      " 15  blk_home         40579 non-null  float64\n",
      " 16  tov_home         40579 non-null  float64\n",
      " 17  pf_home          40579 non-null  float64\n",
      " 18  pts_home         40579 non-null  float64\n",
      " 19  plus_minus_home  40579 non-null  float64\n",
      " 20  elo_home         40579 non-null  float64\n",
      " 21  fgm_away         40579 non-null  float64\n",
      " 22  fga_away         40579 non-null  float64\n",
      " 23  fg_pct_away      40579 non-null  float64\n",
      " 24  fg3m_away        40579 non-null  float64\n",
      " 25  fg3a_away        40579 non-null  float64\n",
      " 26  fg3_pct_away     40579 non-null  float64\n",
      " 27  ftm_away         40579 non-null  float64\n",
      " 28  fta_away         40579 non-null  float64\n",
      " 29  ft_pct_away      40579 non-null  float64\n",
      " 30  oreb_away        40579 non-null  float64\n",
      " 31  dreb_away        40579 non-null  float64\n",
      " 32  reb_away         40579 non-null  float64\n",
      " 33  ast_away         40579 non-null  float64\n",
      " 34  stl_away         40579 non-null  float64\n",
      " 35  blk_away         40579 non-null  float64\n",
      " 36  tov_away         40579 non-null  float64\n",
      " 37  pf_away          40579 non-null  float64\n",
      " 38  pts_away         40579 non-null  float64\n",
      " 39  plus_minus_away  40579 non-null  float64\n",
      " 40  elo_away         40579 non-null  float64\n",
      "dtypes: float64(40), int64(1)\n",
      "memory usage: 12.7 MB\n"
     ]
    }
   ],
   "source": [
    "features, target = get_data()\n",
    "\n",
    "print(f\"{features.shape[0]} games with {features.shape[1]} features\")\n",
    "print(features.columns)\n",
    "\n",
    "features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy of the model will be predicting the home team always wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model\n",
      "Accuracy: 0.6019\n",
      "Precision: 0.6019\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.7515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def find_metrics(labels, pred):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, pred),\n",
    "        'precision': precision_score(labels, pred),\n",
    "        'recall': recall_score(labels, pred),\n",
    "        'f1': f1_score(labels, pred)\n",
    "    }\n",
    "\n",
    "def print_metrics(labels, pred):\n",
    "    metrics = find_metrics(labels, pred)\n",
    "    print(f\"Accuracy: {metrics['accuracy']:0.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:0.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:0.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:0.4f}\")\n",
    "\n",
    "# baseline model\n",
    "baseline_pred = [1] * len(target) # home team always wins\n",
    "print(\"Baseline Model\")\n",
    "print_metrics(target, baseline_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fgm_home', 'fga_home', 'fg_pct_home', 'fg3m_home', 'fg3a_home',\n",
       "       'fg3_pct_home', 'ftm_home', 'fta_home', 'ft_pct_home', 'oreb_home',\n",
       "       'dreb_home', 'reb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home',\n",
       "       'pf_home', 'pts_home', 'plus_minus_home', 'elo_home', 'fgm_away',\n",
       "       'fga_away', 'fg_pct_away', 'fg3m_away', 'fg3a_away', 'fg3_pct_away',\n",
       "       'ftm_away', 'fta_away', 'ft_pct_away', 'oreb_away', 'dreb_away',\n",
       "       'reb_away', 'ast_away', 'stl_away', 'blk_away', 'tov_away', 'pf_away',\n",
       "       'pts_away', 'plus_minus_away', 'elo_away'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `StandardScalar` from `sklearn.preprocessing`, which standardizes data with it's z-score for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalization\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# time series split for cross validation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# classifiers we will use\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For consistency in testing the models, the function below `train`, will be used to return the final test values and predictions of the time-series cross-validation to measure metrics of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, scaler=StandardScaler()):\n",
    "    cv = TimeSeriesSplit()\n",
    "    X_scaled = scaler.fit_transform(X) if scaler else X\n",
    "\n",
    "    for train_index, test_index in cv.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "    return y_test, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5641\n",
      "Precision: 0.5962\n",
      "Recall: 0.7103\n",
      "F1 Score: 0.6483\n",
      "Accuracy: 0.6011\n",
      "Precision: 0.6255\n",
      "Recall: 0.7344\n",
      "F1 Score: 0.6756\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "X, y = get_data()\n",
    "back_test, pred = train(knn, X=X, y=y)\n",
    "print_metrics(back_test, pred)\n",
    "\n",
    "sfs = SequentialFeatureSelector(knn, n_features_to_select=5, n_jobs=-1)\n",
    "sfs.fit(X, y)\n",
    "\n",
    "features = X.columns[sfs.get_support()]\n",
    "X = X[features]\n",
    "\n",
    "X.to_csv('data/best_features_knn.csv', index=False)\n",
    "best_features_knn = pd.read_csv('data/best_features_knn.csv')\n",
    "\n",
    "back_test, pred = train(knn, X=X, y=y)\n",
    "print_metrics(back_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_neighbors: 14\n",
      "Accuracy: 0.6256\n",
      "Precision: 0.6457\n",
      "Recall: 0.7490\n",
      "F1 Score: 0.6935\n"
     ]
    }
   ],
   "source": [
    "def find_best_k(X, y, max_k=15):\n",
    "    best_n = 0\n",
    "    best_score = 0\n",
    "\n",
    "    for k in range(2, max_k):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)\n",
    "        test, pred = train(knn, X=X, y=y)\n",
    "        score = accuracy_score(test, pred)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_n = k\n",
    "\n",
    "    return (best_n, best_score)\n",
    "\n",
    "best_n, best_score = find_best_k(X, y)\n",
    "\n",
    "def print_best_knn(X, y, max_k=15, best_n = 0):\n",
    "    if best_n != 0:\n",
    "        print(f\"Best n_neighbors: {best_n}\")\n",
    "        test, pred = train(KNeighborsClassifier(n_neighbors=best_n), X=X, y=y)\n",
    "        print_metrics(test, pred)\n",
    "        return\n",
    "    best_n, best_score = find_best_k(X, y, max_k)\n",
    "    test, pred = train(KNeighborsClassifier(n_neighbors=best_n), X=X, y=y)\n",
    "    print(f\"Best n_neighbors: {best_n}\")\n",
    "    print_metrics(test, pred)\n",
    "\n",
    "print_best_knn(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "65.11% accuracy is good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression and the SVM with a linear kernel both performed better than the baseline. We will try to improve both models using their hyperparameters. From https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6436\n",
      "Precision: 0.6593\n",
      "Recall: 0.7655\n",
      "F1 Score: 0.7084\n",
      "['fg_pct_home', 'pts_home', 'elo_home', 'ast_away', 'elo_away']\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "logreg = LogisticRegression(max_iter = 1000, n_jobs=-1, verbose=2)\n",
    "X, y = get_data()\n",
    "back_test, pred = train(logreg, X=X, y=y, scaler=scaler)\n",
    "print_metrics(back_test, pred)\n",
    "\n",
    "# find best features using SequentialFeatureSelector\n",
    "sfs = SequentialFeatureSelector(logreg, n_features_to_select=5, cv=cv, n_jobs=-1)\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "sfs.fit(X_scaled, y)\n",
    "\n",
    "# get the best features\n",
    "features = X.columns[sfs.get_support()]\n",
    "X = X[features]\n",
    "print(features.to_list())\n",
    "\n",
    "X.to_csv('data/best_features_logreg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6460\n",
      "Precision: 0.6405\n",
      "Recall: 0.8525\n",
      "F1 Score: 0.7315\n"
     ]
    }
   ],
   "source": [
    "back_test, pred = train(logreg, X=X, y=y, scaler=MinMaxScaler())\n",
    "print_metrics(back_test, pred)\n",
    "#64.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6759\n",
      "Precision: 0.6876\n",
      "Recall: 0.8461\n",
      "F1 Score: 0.7586\n"
     ]
    }
   ],
   "source": [
    "# elo base model\n",
    "elo_home = X['elo_home']\n",
    "elo_preds = [1 if elo_home + 100> elo_away else 0 for elo_home, elo_away in zip(X['elo_home'], X['elo_away']) ]\n",
    "print_metrics(y, elo_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69347923, 0.66020997, 0.67839716, 0.67174331, 0.6435014 ])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), \n",
    "    ('logreg', LogisticRegression(max_iter = 1000, n_jobs=-1, verbose=2))\n",
    "    ])\n",
    "\n",
    "cross_val_score(pipe, X, y, cv=TimeSeriesSplit(n_splits=5),n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_test(data, model, features):\n",
    "    # test the model on previous seasons iteratively\n",
    "    # each iteration, the model is trained on all previous seasons\n",
    "    # and tested on the current season\n",
    "    all_predictions = []\n",
    "    seasons = data['season_id'].unique()\n",
    "\n",
    "    for i in range(2, len(seasons)):\n",
    "        # start on the 3rd season\n",
    "        season = seasons[i]\n",
    "        train = data[data['season_id'] < season]\n",
    "        test = data[data['season_id'] == season]\n",
    "\n",
    "        X = train[features]\n",
    "        y = train['wl_home']\n",
    "\n",
    "        model.fit(X, y)\n",
    "\n",
    "        predictions = model.predict(test[features])\n",
    "        predictions = pd.Series(predictions, index=test.index)\n",
    "\n",
    "        combined = pd.concat([test['wl_home'], predictions], axis=1)\n",
    "        combined.columns = ['actual', 'predicted']\n",
    "\n",
    "        all_predictions.append(combined)\n",
    "    return pd.concat(all_predictions)\n",
    "\n",
    "def pipeline(data, model, n_features):\n",
    "    ignored_cols = ['season_id', 'team_id_home', 'game_id', 'team_id_away', 'wl_home']\n",
    "    feature_cols = data.columns[~data.columns.isin(ignored_cols)]\n",
    "    target_col = 'wl_home'\n",
    "\n",
    "    # 5 fold cross validation for time series data\n",
    "    split = TimeSeriesSplit(n_splits=5)\n",
    "    # finds the best features using sequential feature selector\n",
    "    sfs = SequentialFeatureSelector(model, n_features_to_select=n_features, cv=split, n_jobs=-1)\n",
    "\n",
    "    # normalize the data using min max scaler\n",
    "    data = data.copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    data[feature_cols] = scaler.fit_transform(data[feature_cols])\n",
    "\n",
    "    sfs.fit(data[feature_cols], data[target_col])\n",
    "\n",
    "    best_features = list(feature_cols[sfs.get_support()])\n",
    "    predictions = back_test(data, model, best_features)\n",
    "    print_metrics(predictions['actual'], predictions['predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6717\n",
      "Precision: 0.6894\n",
      "Recall: 0.8274\n",
      "F1 Score: 0.7521\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "pipeline(get_data(), model, 5)\n",
    "\n",
    "\n",
    "# model = KNeighborsClassifier()\n",
    "# pipeline(get_data(), model, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
